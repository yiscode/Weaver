import json, uuid, re, time, argparse, os
from datetime import datetime, timezone
import logging
import torch

import weaviate
from weaviate.classes.config import Property, DataType
from weaviate.classes.query import Filter, Sort
from sentence_transformers import SentenceTransformer
from opencc import OpenCC
from deep_translator import GoogleTranslator

# === è¨­å®š ===
EMBED_MODEL = "BAAI/bge-m3"
COLL = "WorldLoreV2"
BATCH_SIZE = 64  # å·²ç¢ºèª GPU å¯ç”¨ï¼Œå»ºè­°å¯èª¿å¤§è‡³ 64

# è™•ç†å®‰å…¨æª¢æŸ¥å ±éŒ¯ (é‡å° transformers < 4.48 / torch < 2.6)
try:
    import transformers.utils.import_utils as hf_utils
    hf_utils.check_torch_load_is_safe = lambda: None
except:
    pass

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s - %(message)s"
)
log = logging.getLogger("weaver_indexer_gpu")

t2tw = OpenCC('s2twp')

def utc_now_iso() -> str:
    return datetime.now(timezone.utc).isoformat()

def auto_translate_batch(texts):
    """æ‰¹æ¬¡ç¿»è­¯å„ªåŒ–"""
    results = []
    translator = GoogleTranslator(source='en', target='zh-TW')
    for text in texts:
        try:
            if not text or not text.strip():
                results.append("")
                continue
            translated = translator.translate(text)
            results.append(t2tw.convert(translated))
        except Exception as e:
            log.error(f"ç¿»è­¯å‡ºéŒ¯: {e}")
            results.append(text)
    return results

def detect_tags(text, url):
    tags = []
    url_lower = url.lower()
    if any(k in url_lower for k in ["typemoon", "fate"]):
        tags.append("Fate")
    if any(k in url_lower for k in ["projectmoon", "lobotomy", "limbuscompany"]):
        tags.append("ProjectMoon")
    if any(k in url_lower for k in ["darksouls", "dark-souls", "dark-souls-3", "ds3", "ds3remastered"]):
        tags.append("DarkSouls")
    tags.append("Source_EN")
    return list(set(tags))

def stable_uuid(card_id: str, source_url: str) -> str:
    ns = uuid.UUID("12345678-1234-5678-1234-567812345678")
    return str(uuid.uuid5(ns, f"{card_id}|{source_url}"))

def ensure_schema(client):
    if not client.collections.exists(COLL):
        client.collections.create(
            name=COLL,
            properties=[
                Property(name="card_id", data_type=DataType.TEXT),
                Property(name="type", data_type=DataType.TEXT),
                Property(name="name", data_type=DataType.TEXT),
                Property(name="tags", data_type=DataType.TEXT_ARRAY),
                Property(name="text_zh", data_type=DataType.TEXT),
                Property(name="text_original", data_type=DataType.TEXT),
                Property(name="source_url", data_type=DataType.TEXT),
                Property(name="content_hash", data_type=DataType.TEXT),
                Property(name="updated_at", data_type=DataType.DATE),
            ]
        )

def query_latest_project_moon(client):
    """æŸ¥è©¢ DarkSouls æ¨™ç±¤çš„æœ€æ–° 5 ç­†è³‡æ–™"""
    log.info("ğŸ” æ­£åœ¨æŸ¥è©¢ DarkSouls æœ€æ–°è³‡æ–™...")
    coll = client.collections.get(COLL)

    response = coll.query.fetch_objects(
        filters=Filter.by_property("tags").contains_any(["DarkSouls"]),
        sort=Sort.by_property("updated_at", ascending=False),
        limit=5
    )

    for obj in response.objects:
        p = obj.properties
        print(f"[{p.get('updated_at')}] {p.get('name')} (ID: {p.get('card_id')}) (Tags: {p.get('tags')}) (Content: {p.get('text_zh')[:50]}...)")

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--input", default="pm_lore_cleaned.jsonl")
    ap.add_argument("--query", action="store_true", help="åŸ·è¡ŒæŸ¥è©¢è€Œéç´¢å¼•")
    args = ap.parse_args()

    client = weaviate.connect_to_local(port=9080, grpc_port=50051)

    try:
        ensure_schema(client)

        if args.query:
            query_latest_project_moon(client)
            return

        # --- 1. åˆå§‹åŒ– GPU æ¨¡å‹ ---
        device = "cuda" if torch.cuda.is_available() else "cpu"
        log.info(f"æ­£åœ¨è¼‰å…¥æ¨¡å‹è‡³è¨­å‚™: {device}")
        embedder = SentenceTransformer(EMBED_MODEL, device=device)
        if device == "cuda":
            embedder.half()

        coll = client.collections.get(COLL)

        # è®€å–è³‡æ–™
        raw_data_list = []
        with open(args.input, "r", encoding="utf-8") as f:
            for line in f:
                raw_data_list.append(json.loads(line))

        # --- 2. é æª¢ï¼šéæ¿¾é‡è¤‡ UUID ---
        log.info("ğŸ§¹ æ­£åœ¨æª¢æŸ¥é‡è¤‡è³‡æ–™...")
        # è¨ˆç®—æ‰€æœ‰ UUID
        data_map = {}
        for d in raw_data_list:
            uid = stable_uuid(d.get("id"), d.get("source_url"))
            data_map[uid] = d

        # ä¸€æ¬¡æ€§æŸ¥è©¢å·²å­˜åœ¨çš„ UUID (åˆ†æ‰¹æŸ¥è©¢é¿å… URL éé•·)
        existing_uuids = set()
        all_uids = list(data_map.keys())
        for i in range(0, len(all_uids), 100):
            batch_uids = all_uids[i:i+100]
            # æª¢æŸ¥ç‰©ä»¶æ˜¯å¦å­˜åœ¨
            for check_uid in batch_uids:
                if coll.data.exists(check_uid):
                    existing_uuids.add(check_uid)

        to_process_uids = [u for u in all_uids if u not in existing_uuids]
        log.info(f"ç¸½ç­†æ•¸: {len(all_uids)}, å·²å­˜åœ¨: {len(existing_uuids)}, å¾…è™•ç†: {len(to_process_uids)}")

        # --- 3. æ‰¹æ¬¡è™•ç†é‚è¼¯ ---
        for i in range(0, len(to_process_uids), BATCH_SIZE):
            batch_uids = to_process_uids[i : i + BATCH_SIZE]
            batch_data = [data_map[uid] for uid in batch_uids]

            current_batch_texts = [d.get("text_zh") or d.get("text_original", "") for d in batch_data]
            current_batch_names = [d.get("name", "") for d in batch_data]

            log.info(f"æ­£åœ¨è™•ç†æ‰¹æ¬¡ {i//BATCH_SIZE + 1} ({current_batch_names[0]}...)")

            # ç¿»è­¯èˆ‡å‘é‡åŒ–
            translated_texts = auto_translate_batch(current_batch_texts)
            vectors = embedder.encode(translated_texts, batch_size=BATCH_SIZE, convert_to_tensor=False)

            # å¯«å…¥ Weaviate
            with coll.batch.dynamic() as batch:
                for idx, uid in enumerate(batch_uids):
                    item = batch_data[idx]
                    batch.add_object(
                        uuid=uuid.UUID(uid),
                        properties={
                            "card_id": item.get("id"),
                            "type": item.get("type", ""),
                            "name": item.get("name", ""),
                            "tags": detect_tags(item.get("text_original", ""), item.get("source_url", "")),
                            "text_zh": translated_texts[idx],
                            "text_original": item.get("text_original", ""),
                            "source_url": item.get("source_url", ""),
                            "content_hash": item.get("content_hash", ""),
                            "updated_at": utc_now_iso(),
                        },
                        vector=vectors[idx].tolist()
                    )

            if coll.batch.failed_objects:
                log.error(f"æ‰¹æ¬¡å¯«å…¥å¤±æ•—ç­†æ•¸: {len(coll.batch.failed_objects)}")

        log.info("âœ… GPU æ‰¹æ¬¡è™•ç†èˆ‡ Upsert å®Œæˆ")

    finally:
        client.close()

if __name__ == "__main__":
    main()