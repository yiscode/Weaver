# rag_server_memory_v2.py
import os, json
from datetime import datetime, timezone
from typing import Optional

from fastapi import FastAPI, BackgroundTasks, Query, HTTPException, Header
from pydantic import BaseModel

import weaviate
from weaviate.classes.config import Property, DataType
from weaviate.classes.query import Filter

from sentence_transformers import SentenceTransformer, CrossEncoder
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

# === Settings ===
EMBED_MODEL = os.getenv("EMBED_MODEL", "BAAI/bge-m3")
RERANK_MODEL = os.getenv("RERANK_MODEL", "bge-reranker-base")
LLM_URL = os.getenv("LLM_URL", "http://localhost:1337/v1")
LLM_MODEL = os.getenv("LLM_MODEL", "Llama-3_1-8B-Instruct-IQ4_XS")

# Optional debug token header: X-Debug-Token
DEBUG_TOKEN = os.getenv("DEBUG_TOKEN", "")

# Weaviate
client = weaviate.connect_to_local(
    host=os.getenv("WEAVIATE_HOST", "localhost"),
    port=int(os.getenv("WEAVIATE_PORT", "9080")),
    grpc_port=int(os.getenv("WEAVIATE_GRPC_PORT", "50051")),
    skip_init_checks=True,
)

print("Loading Models (this may take a while)...")
text_embedder = SentenceTransformer(EMBED_MODEL)
try:
    reranker = CrossEncoder(RERANK_MODEL)
except Exception:
    reranker = None
    print("Warning: Reranker not found, skipping.")

llm = ChatOpenAI(
    base_url=LLM_URL,
    api_key=os.getenv("LLM_API_KEY", "my-secret-key"),
    model=LLM_MODEL,
    temperature=0.88,
    max_tokens=3000,
    # ç›´æ¥å¯«åœ¨é€™è£¡ï¼Œä¸è¦åŒ…åœ¨ model_kwargs è£¡
    top_p=0.98,
    frequency_penalty=0.8,
    presence_penalty=0.6,
)

app = FastAPI()

# --- utils ---

def utc_now_iso() -> str:
    return datetime.now(timezone.utc).isoformat()


def _ts_to_str(v) -> str:
    if v is None:
        return ""
    if isinstance(v, str):
        return v
    if hasattr(v, "isoformat"):
        return v.isoformat()
    return str(v)

# OpenCC (Traditional Chinese)
try:
    from opencc import OpenCC
    _cc = OpenCC('s2twp')
except Exception:
    _cc = None

def to_traditional_zh(text: str) -> str:
    if not text:
        return text
    return _cc.convert(text) if _cc else text

import re

def light_dedup(text: str) -> str:
    if not text:
        return text
    # é‡å°å¥å­é€²è¡Œå»é‡
    parts = re.split(r"(?<=[ã€‚ï¼ï¼Ÿ])", text)
    seen = set()
    out = []
    for p in parts:
        p_strip = p.strip()
        if not p_strip: continue
        # å¦‚æœå¥å­æ ¸å¿ƒå…§å®¹ï¼ˆå‰10å€‹å­—ï¼‰å·²ç¶“å‡ºç¾éï¼Œå°±ç›´æ¥æ¨æ£„
        core = p_strip[:10]
        if core in seen:
            continue
        seen.add(core)
        out.append(p_strip)
    return "".join(out)


def require_debug_token(x_debug_token: Optional[str]):
    if DEBUG_TOKEN:
        if not x_debug_token or x_debug_token != DEBUG_TOKEN:
            raise HTTPException(status_code=401, detail="Unauthorized")


# --- schema ---

def ensure_schemas():
    if not client.collections.exists("SessionMemory"):
        client.collections.create(
            name="SessionMemory",
            properties=[
                Property(name="session_id", data_type=DataType.TEXT),
                Property(name="role", data_type=DataType.TEXT),
                Property(name="user_name", data_type=DataType.TEXT),
                Property(name="text", data_type=DataType.TEXT),
                Property(name="type", data_type=DataType.TEXT),
                Property(name="timestamp", data_type=DataType.DATE),
            ],
            vectorizer_config=None,
        )

    if not client.collections.exists("WorldState"):
        client.collections.create(
            name="WorldState",
            properties=[
                Property(name="session_id", data_type=DataType.TEXT),
                Property(name="state_json", data_type=DataType.TEXT),
                Property(name="summary", data_type=DataType.TEXT),
                Property(name="version", data_type=DataType.INT),
                Property(name="timestamp", data_type=DataType.DATE),
            ],
            vectorizer_config=None,
        )

ensure_schemas()


class WorldQuery(BaseModel):
    query: str
    user_name: str = "Player"
    session_id: str = "default"
    top_k: int = 5


def _pick_latest_worldstate(ws_objects):
    if not ws_objects:
        return None

    def key(o):
        p = o.properties
        v = p.get("version")
        ts = _ts_to_str(p.get("timestamp"))
        return (v if isinstance(v, int) else -1, ts)

    return sorted(ws_objects, key=key, reverse=True)[0]


def background_update_logic(session_id: str, new_content: str):
    import re
    import json
    print(f"\nğŸ”„ [Background] Updating state for {session_id}...")
    try:
        mem_coll = client.collections.get("SessionMemory")
        ws_coll = client.collections.get("WorldState")
        session_filter = Filter.by_property("session_id").equal(session_id)

        # 1. å–å¾—æ­·å²
        recent = mem_coll.query.fetch_objects(limit=8, filters=session_filter).objects
        # å˜—è©¦æ‰¾å‡º User çš„åå­—
        user_name = next((r.properties.get('user_name') for r in recent if r.properties.get('role') == 'user'), "ç©å®¶")
        chat_log = "\n".join([f"{r.properties.get('user_name')}: {r.properties.get('text')}" for r in recent])

        ws_objs = ws_coll.query.fetch_objects(limit=1, filters=session_filter).objects
        latest_ws = _pick_latest_worldstate(ws_objs)
        prev_state_json = latest_ws.properties.get("state_json") if latest_ws else "{}"
        prev_version = latest_ws.properties.get("version") if latest_ws else 0

        # 2. ç²¾ç°¡åŒ– Promptï¼šå¼·èª¿ã€Œç©å®¶ä¸å±¬æ–¼ NPCã€
        update_prompt = f"""
ä½ æ˜¯ä¸€å€‹ä¸–ç•Œè§€æ•¸æ“šæå–å™¨ã€‚è«‹æ ¹æ“šåŠ‡æƒ…æ›´æ–° JSON æ•¸æ“šã€‚

ã€è­¦å‘Šã€‘ç©å®¶åå­—æ˜¯ã€Œ{user_name}ã€ï¼Œã€Œ{user_name}ã€çš„æ‰€æœ‰å¿ƒç†èˆ‡å‹•ä½œåš´ç¦æ”¾å…¥ "npc" æ¬„ä½ã€‚
"npc" æ¬„ä½åªç´€éŒ„éç©å®¶çš„ç•°æƒ³é«”æˆ–åŒäº‹ã€‚

ã€çµæ§‹éœ€æ±‚ã€‘
{{
  "npc": ["éç©å®¶è§’è‰²çš„ç‹€æ…‹"],
  "places": ["å ´æ™¯æè¿°"],
  "items": ["ç‰©å“æè¿°"],
  "events": ["äº‹ä»¶æ‘˜è¦"]
}}

ã€èˆŠç‹€æ…‹ã€‘: {prev_state_json}
ã€æ–°åŠ‡æƒ…ã€‘: {chat_log}\n{new_content}
""".strip()

        raw_res = llm.invoke([
            SystemMessage(content="You are a JSON formatter. Output ONLY valid JSON. No Markdown. Use single double-quotes for keys."),
            HumanMessage(content=update_prompt)
        ]).content

        print("-" * 30 + "\nã€DEBUG: LLM åŸå§‹å›å‚³ã€‘\n" + raw_res + "\n" + "-" * 30)

        # 3. å¼·åŠ›æ¸…ç†ï¼šä¿®æ­£é›™å¼•è™ŸéŒ¯èª¤
        clean_res = raw_res.replace("```json", "").replace("```", "").strip()
        # å°‡ ""Key"" æ›¿æ›ç‚º "Key"
        clean_res = re.sub(r'""(\w+)""', r'"\1"', clean_res)

        match = re.search(r'(\{.*\})', clean_res, re.DOTALL)
        if not match: raise ValueError("æ‰¾ä¸åˆ° JSON çµæ§‹")

        json_str = match.group(1)
        json_str = re.sub(r'[\x00-\x1F\x7F]', '', json_str) # ç§»é™¤æ§åˆ¶å­—å…ƒ

        try:
            state_data = json.loads(json_str)
        except json.JSONDecodeError:
            # æœ€å¾Œä¸€æ‹›ï¼šç§»é™¤å¤šé¤˜é€—è™Ÿä¸¦ä¿®æ­£ key å¼•è™Ÿ
            json_str = re.sub(r',(\s*[\]\}])', r'\1', json_str)
            json_str = re.sub(r'(?<!")(\b\w+\b)(?!")(?=\s*:)', r'"\1"', json_str)
            state_data = json.loads(json_str)

        new_state_str = json.dumps(state_data, ensure_ascii=False)

        # 4. æ–‡å­¸åŒ–æ•˜äº‹æ‘˜è¦ (ç©å®¶å¿ƒç†æ”¾é€™è£¡ï¼Œè€Œä¸æ˜¯ JSON)
        summary_prompt = f"""
è«‹æ ¹æ“šä»¥ä¸‹ JSON èˆ‡åŠ‡æƒ…ï¼Œæ’°å¯«ä¸€æ®µ 300 å­—çš„æ²‰æµ¸å¼æ•˜äº‹æ‘˜è¦ã€‚
é€™æ®µæ‘˜è¦å°‡ä½œç‚ºä¸‹æ¬¡å°è©±çš„èƒŒæ™¯åƒè€ƒã€‚
ã€è¦æ±‚ã€‘
1. æ·±å…¥æå¯«ç©å®¶è§’è‰²ã€{user_name}ã€‘çš„å¿ƒç†æ¨è«–èˆ‡ä¸å®‰ã€‚
2. æè¿°ç•°æƒ³é«”èˆ‡ç’°å¢ƒçš„å£“æŠ‘æ„Ÿã€‚
3. ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼ˆè‡ºç£ï¼‰ï¼Œç„¡æ¨™ç±¤ã€ç„¡æ¨™é¡Œã€‚
æ•¸æ“šï¼š{new_state_str}
""".strip()

        summary_res = llm.invoke([HumanMessage(content=summary_prompt)]).content
        summary_res = to_traditional_zh(summary_res)

        ws_coll.data.insert(
            properties={
                "session_id": session_id,
                "state_json": new_state_str,
                "summary": summary_res,
                "version": int(prev_version) + 1,
                "timestamp": utc_now_iso(),
            },
            vector=text_embedder.encode(summary_res)
        )
        print(f"âœ… [Background] State updated to v{int(prev_version) + 1}")

    except Exception as e:
        print(f"âŒ [Background] Update failed: {e}")

@app.post("/world")
async def chat_world(q: WorldQuery, background_tasks: BackgroundTasks):
    mem_coll = client.collections.get("SessionMemory")
    ws_coll = client.collections.get("WorldState")

    lore_coll = client.collections.get("WorldLoreV2") if client.collections.exists("WorldLoreV2") else None

    session_filter = Filter.by_property("session_id").equal(q.session_id)

    # 1) Save user input
    mem_coll.data.insert(
        properties={
            "session_id": q.session_id,
            "role": "user",
            "user_name": q.user_name,
            "text": q.query,
            "type": "utterance",
            "timestamp": utc_now_iso(),
        },
        vector=text_embedder.encode(q.query),
    )

    # 2.1) World state
    ws_objs = ws_coll.query.fetch_objects(limit=20, filters=session_filter).objects
    latest_ws = _pick_latest_worldstate(ws_objs)
    ws_summary = latest_ws.properties.get("summary") if latest_ws else "åˆå§‹ç‹€æ…‹"
    ws_summary = to_traditional_zh(ws_summary)

    # 2.2) Recent memory
    recent_mem = mem_coll.query.fetch_objects(limit=12, filters=session_filter).objects
    recent_mem = sorted(recent_mem, key=lambda o: _ts_to_str(o.properties.get("timestamp")))
    history_text = "\n".join([
        f"{m.properties.get('user_name') or m.properties.get('role')}: {m.properties.get('text')}"
        for m in recent_mem
    ])

    # 2.3) Lore retrieval (V2)
    lore_text = ""
    used_lore = []
    if lore_coll is not None:
        q_vec = text_embedder.encode(q.query)
        lore_res = lore_coll.query.near_vector(near_vector=q_vec, limit=max(3, q.top_k)).objects

        chunks = []
        for r in lore_res:
            p = r.properties
            name = p.get("name") or "(æœªå‘½å)"
            ltype = p.get("type") or ""
            txt = p.get("text_zh") or ""
            src = p.get("source_title") or p.get("source_url") or "wiki"
            if txt:
                chunks.append(f"[{ltype}:{name}ï½œ{src}] {txt}")
                used_lore.append({"type": ltype, "name": name, "source": src})
        lore_text = "\n".join(chunks)

    system_prompt = f"""
    ä½ æ˜¯ä¸€ä½å°ˆç²¾æ–¼ã€Œæ–°æœ¬æ ¼æ´¾æ‡¸ç–‘ã€èˆ‡ã€Œå…‹è˜‡é­¯é¢¨æ ¼ã€çš„è³‡æ·± DMã€‚

    ã€èªè¨€é¢¨æ ¼ï¼šåš´ç¦ç¿»è­¯è…”ï¼ˆæ¥µé‡è¦ï¼‰ã€‘
    1. **ç¦æ­¢å†—é•·è™›è©**ï¼šåš´ç¦ä½¿ç”¨ã€Œ...çš„äº‹æƒ…ã€ã€ã€Œ...çš„éƒ¨åˆ†ã€ã€ã€Œ...çš„ä¸€ç¨®...çš„æ„Ÿè¦ºã€ã€ã€Œé€²è¡Œä¸€å€‹...çš„å‹•ä½œã€ã€‚
    2. **ç¦æ­¢è¬ç”¨å‹•è©**ï¼šä¸è¦èªªã€Œæ„Ÿå—åˆ°å£“åŠ›ã€ï¼Œè¦èªªã€Œé‚£è‚¡ç„¡å½¢çš„å£“è¿«æ„Ÿæ­£å•ƒå™¬è‘—ä½ çš„å¾Œé ¸ã€ã€‚
    3. **å°ç£æ–‡å­¸èªæ„Ÿ**ï¼šä½¿ç”¨ç°¡æ½”ã€ç²¾æº–ã€å†·å³»çš„ç¹é«”ä¸­æ–‡ã€‚é¿å…ä½¿ç”¨é•·ä¸²çš„è‹±æ–‡å¼å½¢å®¹è©å­å¥ã€‚
    4. **æ‹’çµ•å¥—è©±**ï¼šåˆªé™¤ã€Œä¸ç¢ºå®šæ„Ÿã€ã€ã€Œæ··åˆè‘—ã€ã€ã€Œä¼¼ä¹æ˜¯ã€ç­‰æ¨¡ç³Šè©å½™ã€‚

    ã€å‹•æ…‹æ•˜äº‹è¦æ±‚ã€‘
    - **æ‹’çµ•éœæ…‹è§€å¯Ÿ**ï¼šä¸è¦åªå¯«ã€Œä½ çš„è¦–ç·šè·Ÿéš¨ã€ï¼Œè¦æå¯«ã€Œè¦–ç¶²è†œæ•æ‰åˆ°çš„æ®˜å½±ã€æˆ–ã€Œè…³æ­¥è²åœ¨ç©ºæ› å¤§å»³ç”¢ç”Ÿçš„è¿´éŸ¿ã€ã€‚
    - **å¿ƒç†èˆ‡ç’°å¢ƒç†”æ¥**ï¼šå°‡ç©å®¶çš„ã€Œå®‰å…¨é¡§å•ã€èƒŒæ™¯èˆ‡ Lore çµåˆã€‚çœ‹åˆ°å“¡å·¥å–Šå«ï¼Œèº«ç‚ºé¡§å•çš„ä½ ï¼Œè…¦ä¸­æ‡‰åå°„æ€§é–ƒéã€Œæ”¶å®¹å¤±æ•ˆç­‰ç´šã€çš„åˆ¤æ–·ï¼Œè€Œä¸æ˜¯åªæ„Ÿåˆ°ä¸é©ã€‚
    - **æ„Ÿå®˜ç´°ç¯€**ï¼šç©ºæ°£ä¸­çš„æƒ¡è‡­ä¸åªæ˜¯æƒ¡è‡­ï¼Œé‚£æ˜¯æ··åˆäº†ã€Œæ¶ˆæ¯’æ°´èˆ‡è…è‚‰ã€çš„ç„¦èºæ°£æ¯ã€‚

    ã€ç›®å‰æƒ…å¢ƒã€‘
    å ´æ™¯æ‘˜è¦ï¼š{ws_summary}
    ç›¸é—œå…§å®¹ï¼ˆLoreï¼‰ï¼š{lore_text}
    è¿‘æœŸè¨˜æ†¶ï¼š{history_text}

    ã€å¯«ä½œæŒ‡ä»¤ã€‘
    è«‹ç›´æ¥å¾ç©å®¶ã€{q.user_name}ã€‘ç›®å‰çš„è™•å¢ƒæ¨é€²ã€‚è«‹å¯«å‡ºè‡³å°‘ 600 å­—ã€å……æ»¿é›»å½±é¡é ­æ„Ÿçš„æ•˜äº‹ã€‚
    ä¸è¦è¤‡è¿°ç©å®¶çš„å‹•ä½œï¼Œè¦æè¿°å‹•ä½œç”¢ç”Ÿçš„ã€Œé‡é‡ã€èˆ‡ã€Œå¾Œæœã€ã€‚
    åš´ç¦æ¨™è¨»ä»»ä½•ã€Œå…§éƒ¨å–®ç™½ã€æˆ–ã€Œå…·è±¡æ„Ÿå®˜ã€ç­‰å­—çœ¼ï¼Œå°‡å®ƒå€‘èå…¥å°èªªç­†è§¸ä¸­ã€‚
    """.strip()
    response = llm.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content=q.query),
    ]).content

    response = light_dedup(to_traditional_zh(response))

    # debug: append citation block (optional)
    if used_lore:
        cites = "ï¼›".join([f"{x['type']}:{x['name']}" for x in used_lore[:3]])
        response += f"\n\nã€æœ¬å›åˆå¼•ç”¨ã€‘{cites}"

    mem_coll.data.insert(
        properties={
            "session_id": q.session_id,
            "role": "assistant",
            "user_name": "DM",
            "text": response,
            "type": "narrative",
            "timestamp": utc_now_iso(),
        },
        vector=text_embedder.encode(response),
    )

    background_tasks.add_task(background_update_logic, q.session_id, response)

    return {
        "content": response,
        "session_id": q.session_id,
        "debug_info": "State updating in background",
    }


# -----------------
# Debug endpoints v3 (V2)
# -----------------

@app.get("/debug/collections")
def debug_collections(x_debug_token: Optional[str] = Header(default=None, alias="X-Debug-Token")):
    require_debug_token(x_debug_token)
    return {
        "collections": [
            {"name": "WorldLoreV2", "exists": client.collections.exists("WorldLoreV2")},
            {"name": "SessionMemory", "exists": client.collections.exists("SessionMemory")},
            {"name": "WorldState", "exists": client.collections.exists("WorldState")},
        ]
    }


@app.get("/debug/lore")
def debug_lore(
    type: Optional[str] = Query(default=None, description="place/npc/item/rule/event/faction/rumor"),
    tag: Optional[str] = Query(default=None, description="å–®ä¸€ tag éæ¿¾ï¼ˆä¾‹å¦‚ è¿·éœ§ï¼‰"),
    source_url: Optional[str] = Query(default=None, description="ä¾†æºç¶²å€ï¼ˆåªçœ‹æŸç¯‡ wiki è’¸é¤¾ï¼‰"),
    limit: int = Query(default=20, ge=1, le=200),
    x_debug_token: Optional[str] = Header(default=None, alias="X-Debug-Token"),
):
    try:
        require_debug_token(x_debug_token)

        if not client.collections.exists("WorldLoreV2"):
            return {"count": 0, "items": []}

        lore = client.collections.get("WorldLoreV2")

        filters = None
        if type:
            filters = Filter.by_property("type").equal(type)
        if source_url:
            f2 = Filter.by_property("source_url").equal(source_url)
            filters = f2 if filters is None else (filters & f2)

        res = lore.query.fetch_objects(limit=min(limit, 200), filters=filters).objects

        if tag:
            res = [o for o in res if tag in (o.properties.get("tags") or [])]

        out = []
        for o in res[:limit]:
            p = o.properties
            out.append({
                "uuid": str(o.uuid),
                "card_id": p.get("card_id"),
                "type": p.get("type"),
                "name": p.get("name"),
                "tags": p.get("tags"),
                "text_zh": p.get("text_zh"),
                "source_url": p.get("source_url"),
                "source_lang": p.get("source_lang"),
                "source_title": p.get("source_title"),
                "updated_at": _ts_to_str(p.get("updated_at")),
            })

        return {"count": len(out), "items": out}
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(error_detail) # é€™æœƒå°åœ¨ä½ çš„çµ‚ç«¯æ©Ÿè¦–çª—
        return {"error": str(e), "detail": "è«‹æŸ¥çœ‹ä¼ºæœå™¨çµ‚ç«¯æ©Ÿè¼¸å‡º"}


@app.get("/debug/session")
def debug_session(
    session_id: str = Query(...),
    limit: int = Query(default=30, ge=1, le=200),
    x_debug_token: Optional[str] = Header(default=None, alias="X-Debug-Token"),
):
    require_debug_token(x_debug_token)

    mem = client.collections.get("SessionMemory")
    session_filter = Filter.by_property("session_id").equal(session_id)
    objs = mem.query.fetch_objects(limit=min(limit, 200), filters=session_filter).objects
    objs = sorted(objs, key=lambda o: _ts_to_str(o.properties.get("timestamp")))

    items = []
    for o in objs[-limit:]:
        p = o.properties
        items.append({
            "uuid": str(o.uuid),
            "timestamp": _ts_to_str(p.get("timestamp")),
            "role": p.get("role"),
            "user_name": p.get("user_name"),
            "type": p.get("type"),
            "text": p.get("text"),
        })

    return {"session_id": session_id, "count": len(items), "items": items}


@app.get("/debug/worldstate")
def debug_worldstate(
    session_id: str = Query(...),
    limit: int = Query(default=20, ge=1, le=200),
    x_debug_token: Optional[str] = Header(default=None, alias="X-Debug-Token"),
):
    require_debug_token(x_debug_token)

    ws = client.collections.get("WorldState")
    session_filter = Filter.by_property("session_id").equal(session_id)
    objs = ws.query.fetch_objects(limit=min(limit, 200), filters=session_filter).objects
    latest = _pick_latest_worldstate(objs)

    if not latest:
        return {"session_id": session_id, "exists": False}

    p = latest.properties
    return {
        "session_id": session_id,
        "exists": True,
        "uuid": str(latest.uuid),
        "version": p.get("version"),
        "timestamp": _ts_to_str(p.get("timestamp")),
        "summary": p.get("summary"),
        "state_json": p.get("state_json"),
    }
@app.post("/reset")
def reset_session(session_id: str = Query(...)):
    try:
        # 1. æ¸…ç†ç‹€æ…‹ (WorldState)
        ws_coll = client.collections.get("WorldState")
        ws_coll.data.delete_many(where=Filter.by_property("session_id").equal(session_id))

        # 2. æ¸…ç†æ­·å²ç´€éŒ„ (SessionMemory) - é€™æ˜¯è§£æ±ºé‡è¤‡å­—è©çš„é—œéµ
        mem_coll = client.collections.get("SessionMemory")
        mem_coll.data.delete_many(where=Filter.by_property("session_id").equal(session_id))

        return {"msg": f"Session {session_id} has been completely wiped."}
    except Exception as e:
        return {"error": str(e)}
@app.get("/debug/history")
def debug_history(session_id: str = Query(...)):
    mem_coll = client.collections.get("SessionMemory")
    res = mem_coll.query.fetch_objects(
        filters=Filter.by_property("session_id").equal(session_id),
        limit=20
    ).objects

    out = []
    for o in res:
        out.append({
            "role": o.properties.get("role"),
            "content": o.properties.get("content")[:30] + "...", # åªçœ‹é–‹é ­
            "time": str(o.properties.get("timestamp"))
        })
    return {"count": len(out), "history": out}

@app.on_event("shutdown")
def shutdown():
    client.close()
